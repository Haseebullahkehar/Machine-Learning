{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NAIVE BAYES ML MODELS**\n",
    "\n",
    ". Naive Bayes is a simple supervised machine learning algorithm.\n",
    "\n",
    ". Naive Bayes is a family of probabilistic algorithms primarily used for classification problems.\n",
    "\n",
    ". The algorithm is based on applying Bayes' theorem and assuming conditional independence given the class label.\n",
    "\n",
    ". It is a simple yet effective method for many classification tasks, especially with text data(e.g, spam filtering or sentiment analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are three main types of Naive Bayes\n",
    "\n",
    "1. **Guassian Naive Bayes**\n",
    "    . This algorithm is used for continuous numerical features that are assumed to follow a normal distribution (also knows as Guassian distribution).\n",
    "     . In Guassian Naive Bayes, the likelihood probability P(features | class) is modeled using the normal distribution with a mean and variance estimated from the training data.\n",
    "\n",
    " **2. Multinomial Naive Bayes**    \n",
    "       . This algorithm is used for discrete count data such as word counts in text classification.\n",
    "       . In Multinomial Naive Bayes, the likelihood probability P(features | class) is modeled using the Multinomial distribution, which models the probability of observing a feature count given the class label.\n",
    "\n",
    "  **3. Bernoulli Naive Bayes**\n",
    "       . This algorithm is also used for discrete count data such as word counts in text classification , but the features are binary (0 or 1) instead of counts.\n",
    "        . In Bernoulli Naive Bayes, the likelihood probability P(features |  class) is modeled using the Bernoulli distribution, which models the probability of observing a feature given the class label as a binary variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guassian Naive Bayes accuracy: 0.9777777777777777\n",
      "Multinomial Naive Bayes accuracy: 0.9555555555555556\n",
      "Bernoulli Naive Bayes accuracy: 0.28888888888888886\n",
      "Complement Naive Bayes accuracy: 0.7111111111111111\n",
      "---------------------------\n",
      "Best model: 0.9777777777777777\n",
      "Best accuracy: Guassian\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, ComplementNB\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "# load the iris dataset \n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target \n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Naive Bayes models \n",
    "gnb = GaussianNB()\n",
    "mnb = MultinomialNB()\n",
    "bnb = BernoulliNB()\n",
    "cnb = ComplementNB()\n",
    "\n",
    "# Train the models on the training set \n",
    "gnb.fit(X_train, y_train)\n",
    "mnb.fit(X_train, y_train)\n",
    "bnb.fit(X_train, y_train)\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set using each model\n",
    "gnb_pred = gnb.predict(X_test)\n",
    "mnb_pred = mnb.predict(X_test)\n",
    "bnb_pred = bnb.predict(X_test)\n",
    "cnb_pred = cnb.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy scores for each model\n",
    "gnb_score = accuracy_score(y_test, gnb_pred)\n",
    "mnb_score = accuracy_score(y_test, mnb_pred)\n",
    "bnb_score = accuracy_score(y_test, bnb_pred)\n",
    "cnb_score = accuracy_score(y_test, cnb_pred)\n",
    "\n",
    "# Print the accuracy scores\n",
    "print(\"Guassian Naive Bayes accuracy:\", gnb_score)\n",
    "print(\"Multinomial Naive Bayes accuracy:\", mnb_score)\n",
    "print(\"Bernoulli Naive Bayes accuracy:\", bnb_score)\n",
    "print(\"Complement Naive Bayes accuracy:\", cnb_score)\n",
    "\n",
    "# Select the best model based on the accuracy score \n",
    "best_model = max([(gnb_score, 'Guassian'), (mnb_score, 'Multinomial'), (bnb_score, 'Bernoulli'), (cnb_score, 'Complement')])\n",
    "# print a separating line in output \n",
    "print(\"---------------------------\")\n",
    "\n",
    "print(\"Best model:\", best_model[1])\n",
    "print(\"Best accuracy:\", best_model[0])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **same code using for loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes accuracy: 0.9777777777777777\n",
      "Multinomial Naive Bayes accuracy: 0.9555555555555556\n",
      "Bernoulli Naive Bayes accuracy: 0.28888888888888886\n",
      "Complement Naive Bayes accuracy: 0.7111111111111111\n",
      "---------------------------\n",
      "Best model: Gaussian\n",
      "Best accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, ComplementNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load the iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Naive Bayes models\n",
    "models = {\n",
    "    'Gaussian': GaussianNB(),\n",
    "    'Multinomial': MultinomialNB(),\n",
    "    'Bernoulli': BernoulliNB(),\n",
    "    'Complement': ComplementNB()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Naive Bayes accuracy: {accuracy}\")\n",
    "\n",
    "# Find the best model based on accuracy\n",
    "best_model_name, best_model = max(models.items(), key=lambda x: accuracy_score(y_test, x[1].predict(X_test)))\n",
    "print(\"---------------------------\")\n",
    "print(\"Best model:\", best_model_name)\n",
    "print(\"Best accuracy:\", accuracy_score(y_test, best_model.predict(X_test)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
